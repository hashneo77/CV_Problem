{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.457375\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "with open('train_image.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open('train_label.pkl', 'rb') as f:\n",
    "    label = pickle.load(f)\n",
    "with open('test_image.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "label=np.asarray(label)\n",
    "data=np.asarray(data)\n",
    "test_data=test_data/255\n",
    "test_data=np.asarray(test_data)\n",
    "for i in range(8000):\n",
    "    if label[i]==2:\n",
    "        label[i]=1\n",
    "    elif label[i]==3:\n",
    "        label[i]=2\n",
    "    elif label[i]==6:\n",
    "        label[i]=3\n",
    "class NeuralNet:\n",
    "    def __init__(self,num_hidden,num_neuron,learning_rate):\n",
    "        self.num_input=8000                  #took the 7000 samples given for training\n",
    "        self.dimension=784        \n",
    "        self.num_out=4                      #output is 10 classes\n",
    "        self.layers=[]\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        self.num_hidden=num_hidden\n",
    "        self.num_neuron=num_neuron\n",
    "        self.learning_rate=learning_rate\n",
    "        self.X_train=np.zeros((8000,784))     #change 7000 to 60,000 if you want to use the full MNIST dataset\n",
    "        self.Y_train=np.zeros(8000)           #change 7000 to 60,000 if you want to use the full MNIST dataset\n",
    "        self.d_weights=[]\n",
    "        self.d_bias=[]\n",
    "        self.d_layers=[]\n",
    "        self.Y_train_hot=np.zeros((8000,4)) #change 7000 to 60,000 if you want to use the full MNIST dataset\n",
    "    \n",
    "    def relu(self,x):                         #relu for nonlinearity\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def get_data(self):                       # getting the data\n",
    "        #Data= np.genfromtxt(r'mnist_train.csv', delimiter=',')\n",
    "        self.Y_train=label\n",
    "        self.X_train=data/255\n",
    "        self.Y_train=self.Y_train.astype(int)\n",
    "        self.Y_train_hot[range(self.num_input),self.Y_train]=1          #one hot representation of training examples\n",
    "        \n",
    "    def weight_inialization(self):           #initialising the weights for each layer performance can change with values of alpha\n",
    "        self.get_data()\n",
    "        alpha=.1\n",
    "        W=alpha*np.random.randn(self.dimension,self.num_neuron)\n",
    "        self.weights.append(W)\n",
    "        b=np.zeros((1,self.num_neuron))\n",
    "        self.bias.append(b)\n",
    "        for i in range(1,self.num_hidden):\n",
    "            W=alpha*np.random.randn(self.num_neuron,self.num_neuron)\n",
    "            self.weights.append(W)\n",
    "            b=np.zeros((1,self.num_neuron))\n",
    "            self.bias.append(b)\n",
    "        W=alpha*np.random.randn(self.num_neuron,self.num_out)\n",
    "        self.weights.append(W)\n",
    "        b=np.zeros((1,self.num_out))\n",
    "        self.bias.append(b)\n",
    "                           \n",
    "    def forward_pass(self):                 #normal forward pass\n",
    "        j=0\n",
    "        self.layers=[]\n",
    "        self.layers.append(np.dot(self.X_train,self.weights[j])+self.bias[j])\n",
    "        for i in range(1,self.num_hidden):\n",
    "            j=j+1\n",
    "            self.layers.append(self.relu((np.dot(self.layers[j-1],self.weights[j])+self.bias[j])))\n",
    "        x=np.exp((np.dot(self.layers[j],self.weights[j+1]))+self.bias[j+1])\n",
    "        x=x/np.sum(x,axis=1,keepdims=True)\n",
    "        self.layers.append(x)\n",
    "        \n",
    "    def back_pass(self):                   #backprop \n",
    "        j=0\n",
    "        k=self.num_hidden\n",
    "        self.d_layers=[]\n",
    "        self.d_weights=[]\n",
    "        self.d_bias=[]                                                           #first layer and last layer backprop have to explicitly written\n",
    "        self.d_layers.append((self.layers[k]-self.Y_train_hot)/self.num_input)\n",
    "        self.d_weights.append(np.dot((self.layers[k-1]).T,self.d_layers[j]))\n",
    "        self.d_bias.append(np.sum(self.d_layers[j],axis=0,keepdims=True))\n",
    "        for i in range(1,self.num_hidden):\n",
    "            j=j+1\n",
    "            self.d_layers.append(np.dot(self.d_layers[j-1],(self.weights[k]).T))\n",
    "            W=self.d_layers[j]\n",
    "            W[self.layers[k-1]<=0]=0\n",
    "            self.d_layers[j]=W\n",
    "            k=k-1\n",
    "            self.d_weights.append(np.dot((self.layers[k-1]).T,self.d_layers[j]))\n",
    "            self.d_bias.append(np.sum(self.d_layers[j],axis=0,keepdims=True))\n",
    "        self.d_layers.append(np.dot(self.d_layers[j],(self.weights[k]).T))\n",
    "        self.d_weights.append(np.dot((self.X_train).T,self.d_layers[j+1]))\n",
    "        self.d_bias.append(np.sum(self.d_layers[j+1],axis=0,keepdims=True))\n",
    "        \n",
    "    def weight_updation(self):      #updating the weight\n",
    "        k=self.num_hidden\n",
    "        for i in range(self.num_hidden):\n",
    "            self.weights[i]+=-self.learning_rate*self.d_weights[k]\n",
    "            self.bias[i]+=-self.learning_rate*self.d_bias[k]\n",
    "            k=k-1\n",
    "            \n",
    "    def error(self):\n",
    "        loss=0.5*np.sum(np.square((self.layers[self.num_hidden]-self.Y_train_hot)))/8000\n",
    "        return (loss)\n",
    "    \n",
    "    def accuracy(self):\n",
    "        count=0\n",
    "        predicted=np.argmax(self.layers[self.num_hidden],axis=1)\n",
    "        for i in range(self.num_input):\n",
    "            if(predicted[i]==self.Y_train[i]):\n",
    "                count+=1\n",
    "        count=count/self.num_input\n",
    "        print(count)\n",
    "        \n",
    "    def train(self):\n",
    "        epoch=5000      # change the epochs to see the variation\n",
    "        self.weight_inialization()\n",
    "        for i in range(epoch):\n",
    "            self.forward_pass()\n",
    "            self.back_pass()\n",
    "            self.weight_updation()\n",
    "            #print(self.error())\n",
    "            #print(self.error())\n",
    "            \n",
    "    def test(self):\n",
    "        #test_data= np.genfromtxt(r'C:\\Users\\hari\\ml_assignment\\mnist_test.csv', delimiter=',')\n",
    "        #test_data=test_data/255\n",
    "        j=0\n",
    "        self.layers=[]\n",
    "        self.layers.append(np.dot(test_data,self.weights[j])+self.bias[j])\n",
    "        for i in range(1,self.num_hidden):\n",
    "            j=j+1\n",
    "            self.layers.append(self.relu((np.dot(self.layers[j-1],self.weights[j])+self.bias[j])))\n",
    "        x=np.exp((np.dot(self.layers[j],self.weights[j+1]))+self.bias[j+1])\n",
    "        x=x/np.sum(x,axis=1,keepdims=True)\n",
    "        self.layers.append(x)\n",
    "        predicted=np.argmax(self.layers[self.num_hidden],axis=1)\n",
    "        predicted=predicted.astype(int)\n",
    "        print(np.shape(predicted))\n",
    "        np.savetxt(\"test_result_joseph.csv\", predicted, fmt='%10.0f', delimiter='\\t')\n",
    "\n",
    "Net1=NeuralNet(2,300,.1) #declare as NeuralNet(number of hidden layers,number of neurons in hidden layer,learning rate)\n",
    "Net1.train()\n",
    "Net1.accuracy()          #training set accuracy\n",
    "Net1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-9d96eb8a2407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "np.shape(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
